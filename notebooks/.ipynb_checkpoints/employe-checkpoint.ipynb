{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "adfbe30e-7ebb-0f88-d917-d9a8f97c638e",
    "_uuid": "d3fb8901aee3f95962b3281c19ebe619c20936c7"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import statements required for Plotly \n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, log_loss, classification_report)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost\n",
    "\n",
    "# Import and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e035b071-50f8-43ca-9611-fc47272bb05e",
    "_uuid": "55739699338c15cd5c11e609bf3106c1620df91e"
   },
   "outputs": [],
   "source": [
    "attrition = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57e2bf45-5920-af03-50c1-b5bba334eb11",
    "_uuid": "572b04ffd595155966d85e6999a801425cacff99"
   },
   "outputs": [],
   "source": [
    "# Looking for NaN\n",
    "display(attrition.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4bbd2965-fb1f-6a9d-6661-cb02988c2299",
    "_uuid": "330a6b49a9053567af459472c286adc71594f473"
   },
   "outputs": [],
   "source": [
    "# Plotting the KDEplots\n",
    "f, axes = plt.subplots(3, 3, figsize=(10, 8), \n",
    "                       sharex=False, sharey=False)\n",
    "\n",
    "# Defining our colormap scheme\n",
    "s = np.linspace(0, 3, 10)\n",
    "cmap = sns.cubehelix_palette(start=0.0, light=1, as_cmap=True)\n",
    "\n",
    "# Generate and plot\n",
    "x = attrition['Age'].values\n",
    "y = attrition['TotalWorkingYears'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True, cut=5, ax=axes[0,0])\n",
    "axes[0,0].set( title = 'Age against Total working years')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=0.333333333333, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['Age'].values\n",
    "y = attrition['DailyRate'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True, ax=axes[0,1])\n",
    "axes[0,1].set( title = 'Age against Daily Rate')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=0.666666666667, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['YearsInCurrentRole'].values\n",
    "y = attrition['Age'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True, ax=axes[0,2])\n",
    "axes[0,2].set( title = 'Years in role against Age')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=1.0, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['DailyRate'].values\n",
    "y = attrition['DistanceFromHome'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,0])\n",
    "axes[1,0].set( title = 'Daily Rate against DistancefromHome')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=1.333333333333, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['DailyRate'].values\n",
    "y = attrition['JobSatisfaction'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,1])\n",
    "axes[1,1].set( title = 'Daily Rate against Job satisfaction')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=1.666666666667, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['YearsAtCompany'].values\n",
    "y = attrition['JobSatisfaction'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,2])\n",
    "axes[1,2].set( title = 'Daily Rate against distance')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=2.0, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['YearsAtCompany'].values\n",
    "y = attrition['DailyRate'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,0])\n",
    "axes[2,0].set( title = 'Years at company against Daily Rate')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=2.333333333333, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['RelationshipSatisfaction'].values\n",
    "y = attrition['YearsWithCurrManager'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,1])\n",
    "axes[2,1].set( title = 'Relationship Satisfaction vs years with manager')\n",
    "\n",
    "cmap = sns.cubehelix_palette(start=2.666666666667, light=1, as_cmap=True)\n",
    "# Generate and plot\n",
    "x = attrition['WorkLifeBalance'].values\n",
    "y = attrition['JobSatisfaction'].values\n",
    "sns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,2])\n",
    "axes[2,2].set( title = 'WorklifeBalance against Satisfaction')\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f44820b-847c-5465-3251-e6e69ac4c3fe",
    "_uuid": "25a7b556eece35ea3b32beb50d342e663905f61b"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary for the target mapping\n",
    "target_map = {'Yes':1, 'No':0}\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "attrition[\"Attrition_numerical\"] = attrition[\"Attrition\"].apply(lambda x: target_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2266ca6-3589-f065-4ca3-f3a8fe558000",
    "_uuid": "be8292954823fb97dd7ed27096d15c8d0cb267e2"
   },
   "outputs": [],
   "source": [
    "# creating a list of only numerical values\n",
    "numerical = [u'Age', u'DailyRate', u'DistanceFromHome', \n",
    "             u'Education', u'EmployeeNumber', u'EnvironmentSatisfaction',\n",
    "             u'HourlyRate', u'JobInvolvement', u'JobLevel', u'JobSatisfaction',\n",
    "             u'MonthlyIncome', u'MonthlyRate', u'NumCompaniesWorked',\n",
    "             u'PercentSalaryHike', u'PerformanceRating', u'RelationshipSatisfaction',\n",
    "             u'StockOptionLevel', u'TotalWorkingYears',\n",
    "             u'TrainingTimesLastYear', u'WorkLifeBalance', u'YearsAtCompany',\n",
    "             u'YearsInCurrentRole', u'YearsSinceLastPromotion',u'YearsWithCurrManager']\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= attrition[numerical].astype(float).corr().values, # Generating the Pearson correlation\n",
    "        x=attrition[numerical].columns.values,\n",
    "        y=attrition[numerical].columns.values,\n",
    "        colorscale='Viridis',\n",
    "        reversescale = False,\n",
    "#         text = True ,\n",
    "        opacity = 1.0\n",
    "        \n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Pearson Correlation of numerical features',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ),\n",
    "    width = 900, height = 700,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aaecd545-abb3-0513-5ae5-fc178f7e5de3",
    "_uuid": "0bdad6dd0a36507f1fffb6146d9f499f7bcff60f",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Refining our list of numerical variables\n",
    "numerical = [u'Age', u'DailyRate',  u'JobSatisfaction',\n",
    "       u'MonthlyIncome', u'PerformanceRating',\n",
    "        u'WorkLifeBalance', u'YearsAtCompany', u'Attrition_numerical']\n",
    "\n",
    "#g = sns.pairplot(attrition[numerical], hue='Attrition_numerical', palette='seismic', diag_kind = 'kde',diag_kws=dict(shade=True))\n",
    "#g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "937385c7-7b7f-f6d0-d974-0527a7118e98",
    "_uuid": "93c57827699653ac22b1c38410fef98bb849bf11"
   },
   "outputs": [],
   "source": [
    "# Drop the Attrition_numerical column from attrition dataset first - Don't want to include that\n",
    "attrition = attrition.drop(['Attrition_numerical'], axis=1)\n",
    "\n",
    "# Empty list to store columns with categorical data\n",
    "categorical = []\n",
    "for col, value in attrition.iteritems():\n",
    "    if value.dtype == 'object':\n",
    "        categorical.append(col)\n",
    "\n",
    "# Store the numerical columns in a list numerical\n",
    "numerical = attrition.columns.difference(categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "29b16ff2-e3bb-bb81-348c-995553409ad0",
    "_uuid": "c6c16d9a96377ef56b52309b62058f980532211a"
   },
   "source": [
    "Having identified which of our features contain categorical data, we can set about numerically encoding the data. To do this, I shall use the **get_dummies** method from Pandas which creates encoded dummy variables from the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ec5cd49-f8b3-e36b-75dd-ac95fe0373ac",
    "_uuid": "991b9e3a9c2ff8b8a44409735d276a8af6af9073"
   },
   "outputs": [],
   "source": [
    "# Store the categorical data in a dataframe called attrition_cat\n",
    "attrition_cat = attrition[categorical]\n",
    "attrition_cat = attrition_cat.drop(['Attrition'], axis=1) # Dropping the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ea5b0d8-1f13-e56b-72cf-bcbe7dd6fad2",
    "_uuid": "1fc7602692b1c0ddb8c691b513eb747f59322ef0"
   },
   "outputs": [],
   "source": [
    "attrition_cat = pd.get_dummies(attrition_cat)\n",
    "attrition_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de8b3a57-6aba-eae7-2be3-dbe0ae761d6a",
    "_uuid": "34c6c46ec2ac73d8037610b8edee0c2fcd0f7343"
   },
   "outputs": [],
   "source": [
    "# Store the numerical features to a dataframe attrition_num\n",
    "attrition_num = attrition[numerical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9de23a93-10b6-33b8-eea8-0cf44c6e5e08",
    "_uuid": "accb0cea4902bdd127509d431cca7faa731fa7d8"
   },
   "source": [
    "Having encoded our categorical columns as well as engineering and created some new features from the numerical data, we can now proceed to merging both dataframes into a final set with which we will train and test our models on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b90b69ba-f19d-0707-7c2c-183b8d01130f",
    "_uuid": "db54c5eae249c7cf8bc038057b470c369da9ab4d"
   },
   "outputs": [],
   "source": [
    "# Concat the two dataframes together columnwise\n",
    "attrition_final = pd.concat([attrition_num, attrition_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfa5e82f-2dd3-1bee-5b2b-367468be7040",
    "_uuid": "855f088cc5ba3d867269f2e6655a34880f8273f2"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary for the target mapping\n",
    "target_map = {'Yes':1, 'No':0}\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "target = attrition[\"Attrition\"].apply(lambda x: target_map[x])\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f56b814-92a6-3042-461e-44f9e6352e86",
    "_uuid": "3fcbd2a08a0b57db358997809c190d210848d965"
   },
   "source": [
    "However just by a quick inspection of the counts of the number of 'Yes' and 'No' in the target variable tells us that there is quite a large skew in target as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f47479ed-e975-413d-37f6-e6ad58342b6d",
    "_uuid": "514395b7b9952a194156772663e6c90a8cf257e6"
   },
   "outputs": [],
   "source": [
    "data = [go.Bar(\n",
    "            x=attrition[\"Attrition\"].value_counts().index.values,\n",
    "            y= attrition[\"Attrition\"].value_counts().values\n",
    "    )]\n",
    "\n",
    "py.iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "891264f0-63f0-fb53-c8c2-f9ceb6b7f00d",
    "_uuid": "68c440e6a284a355fded2a37fcb171e7750574e8"
   },
   "source": [
    "Therefore we have to keep in mind that there is quite a big imbalance in our target variable. Many statistical techniques have been put forth to treat imbalances in data (oversampling or undersampling). In this notebook, I will use an oversampling technique known as SMOTE to treat this imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c197f8ee-76b0-7137-f001-83f969637521",
    "_uuid": "73ef3aca741a60167c23f1c0dfe67893dbecbd84"
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split method\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# Split data into train and test sets as well as for validation and testing\n",
    "train, test, target_train, target_val = train_test_split(attrition_final, \n",
    "                                                         target, \n",
    "                                                         train_size= 0.80,\n",
    "                                                         random_state=0);\n",
    "#train, test, target_train, target_val = StratifiedShuffleSplit(attrition_final, target, random_state=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a865e8bc-21c0-b8a6-85f2-60804b027103",
    "_uuid": "1f46ca63da902feaede091fa88f4b39d4574fe33"
   },
   "outputs": [],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "smote_train, smote_target = oversampler.fit_sample(train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdb4257b-8307-e96e-bf5b-09a724e609b0",
    "_uuid": "4878a2b91492f6b2409e83cd61fe77844ca7220e"
   },
   "source": [
    "**Initialising Random Forest parameters**\n",
    "\n",
    "We will utilise the Scikit-learn library to construct a Random Forest model. To do so, we have to first define our set of parameters that we will feed into our Random Forest classifier as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89521bf0-95f5-de1d-a4f9-a981c564aa55",
    "_uuid": "4742119208a704a9d196723c27c1a074a9655feb"
   },
   "outputs": [],
   "source": [
    "seed = 0   # We set our random seed to zero for reproducibility\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 1000,\n",
    "#     'warm_start': True, \n",
    "    'max_features': 0.3,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : seed,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4af80e2-032d-db67-b1ec-6691eb57563a",
    "_uuid": "a1c1bb566236cfc1d95f82a36910aa457d4e1a42"
   },
   "source": [
    "Having defined our parameters, we can initialise a Random Forest object by using scikit-learn's **RandomForestClassifier** and unpacking the parameters by adding the double asterisks symbols as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04516a2f-0cd3-b521-160a-614c6421cab0",
    "_uuid": "5f35121c811cc6b28cb94044c4d3738f9e3adc6f"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7445e9fc-9434-3e99-3f18-0e72dd1963be",
    "_uuid": "10b0a85eec9ed3f34f7cd13c66bf051c4b20d408"
   },
   "source": [
    "The next step after prepping our Random Forest model would be to start building a forest of trees using our training set and fitting it to our attrition target variable. We do so by simply using the **fit** call as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c1a0e3e-ccbb-8b33-2c79-23800a893523",
    "_uuid": "2e94857019a23efbe12819381c29053e766ad842"
   },
   "outputs": [],
   "source": [
    "rf.fit(smote_train, smote_target)\n",
    "print(\"Fitting of Random Forest finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c20ee19d-075b-0b58-6eb3-25c9bd93ceeb",
    "_uuid": "d790d7f68a918ef17699fe46e09484d893fc0b53"
   },
   "source": [
    "Having fitted our forest of trees with our parameters to the training set against our target variable, we now have a learning model **rf** which we can make predictions out of. To use our Random Forest in predicting against our test data, we can use sklearn's **.predict** method as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2f76111-da81-dc47-5075-76de75ee7636",
    "_uuid": "94bebdcf45d66f479424618ba91ecacf8bfce142"
   },
   "outputs": [],
   "source": [
    "rf_predictions = rf.predict(test)\n",
    "print(\"Predictions finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "14046a92-63a3-b7ef-f26f-c782816c1c4c",
    "_uuid": "5361cf75ae75d4abab3ac62e870f449537b46ab6"
   },
   "source": [
    "Scoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f212f92-952b-e4a8-ac8f-c3349ca91dde",
    "_uuid": "7d0997baaafcdf2cc452d5b1d298cee757a55526"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy score: {}\".format(accuracy_score(target_val, rf_predictions)))\n",
    "print(\"=\"*80)\n",
    "print(classification_report(target_val, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a44123f-4630-4125-cc60-745b60ac0073",
    "_uuid": "a170a30868ecbb5c58841358e71ac3f98abd53de"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = rf.feature_importances_,\n",
    "    x = attrition_final.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = rf.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = attrition_final.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Random Forest Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 5,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ebaae88e-3aea-ec26-4ae0-65227a857eaf",
    "_uuid": "b0254d0f5318012fdf0ebaab37296187eee372fe"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "decision_tree.fit(train, target_train)\n",
    "\n",
    "# Predicting results for test dataset\n",
    "y_pred = decision_tree.predict(test)\n",
    "\n",
    "# Export our trained model as a .dot file\n",
    "with open(\"tree1.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(decision_tree,\n",
    "                              out_file=f,\n",
    "                              max_depth = 4,\n",
    "                              impurity = False,\n",
    "                              feature_names = attrition_final.columns.values,\n",
    "                              class_names = ['No', 'Yes'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "        \n",
    "#Convert .dot to .png to allow display in web notebook\n",
    "check_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n",
    "\n",
    "# Annotating chart with PIL\n",
    "img = Image.open(\"tree1.png\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "img.save('sample-out.png')\n",
    "PImage(\"sample-out.png\", height=2000, width=1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2f3de1c-8b21-7f2a-244b-429e4ae22786",
    "_uuid": "fdc8e174c321244fa56c77158979d4f204ba6f6b"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Parameters\n",
    "gb_params ={\n",
    "    'n_estimators': 1500,\n",
    "    'max_features': 0.9,\n",
    "    'learning_rate' : 0.25,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'subsample': 1,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : seed,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed6a837e-2864-291c-be8d-3c8e9ed900b7",
    "_uuid": "36e6b84adb38f10b45ec68988d2efea3b0ca16a5"
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(**gb_params)\n",
    "# Fit the model to our SMOTEd train and target\n",
    "gb.fit(smote_train, smote_target)\n",
    "# Get our predictions\n",
    "gb_predictions = gb.predict(test)\n",
    "print(\"Predictions have finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40c37011-76df-fcc7-9cd0-e689374a8d1a",
    "_uuid": "a83cd7638c20011e62af71ef073b7728bce53754"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(target_val, gb_predictions))\n",
    "print(classification_report(target_val, gb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "082ca641-ffd2-fc3b-a7b6-9418b08767d9",
    "_uuid": "900258bf0d0d8c84a8850e0e2ca50e0eedaae8ee"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = gb.feature_importances_,\n",
    "    x = attrition_final.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = gb.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = attrition_final.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Gradient Boosting Model Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 5,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
